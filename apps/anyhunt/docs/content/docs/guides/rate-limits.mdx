---
title: Rate Limits
description: Understand quota and concurrency limits for your plan
---

# Rate Limits

Anyhunt uses rate limits to ensure fair usage and service reliability. Understanding these limits helps you build robust integrations.

## Types of Limits

### Request Rate Limit

Maximum requests per minute per API key:

| Plan | Requests/minute |
|------|-----------------|
| Free | 10 |
| Basic | 30 |
| Pro | 60 |
| Team | 120 |

### Concurrency Limit

Maximum simultaneous operations being processed:

| Plan | Concurrent |
|------|------------|
| Free | 2 |
| Basic | 5 |
| Pro | 10 |
| Team | 20 |

### Monthly Quota

Total API calls per billing cycle (includes all API types):

| Plan | Monthly Quota |
|------|---------------|
| Free | 100 |
| Basic | 5,000 |
| Pro | 20,000 |
| Team | 60,000 |

## API-Specific Limits

Different APIs have different resource costs:

| API | Credits per Call | Notes |
|-----|------------------|-------|
| Scrape | 1 | Per page scraped |
| Crawl | 1 per page | Total pages crawled |
| Map | 1 | Per sitemap request |
| Batch Scrape | 1 per URL | Total URLs in batch |
| Extract | 2-5 | Varies by complexity |
| Search | 1 | Per search query |
| Search + Scrape | 1 + 1 per result | When `scrapeResults: true` |

### Crawl Limits

| Plan | Max Pages/Crawl | Max Depth |
|------|-----------------|-----------|
| Free | 10 | 2 |
| Basic | 100 | 3 |
| Pro | 500 | 5 |
| Team | 2,000 | 10 |

### Batch Scrape Limits

| Plan | Max URLs/Batch |
|------|----------------|
| Free | 5 |
| Basic | 20 |
| Pro | 50 |
| Team | 100 |

## Rate Limit Headers

Every response includes rate limit information:

```
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1704067200
```

| Header | Description |
|--------|-------------|
| `X-RateLimit-Limit` | Max requests per window |
| `X-RateLimit-Remaining` | Remaining requests |
| `X-RateLimit-Reset` | Unix timestamp when limit resets |

## Handling Rate Limits

When rate limited, you'll receive:

```json
{
  "success": false,
  "error": {
    "code": "RATE_LIMITED",
    "message": "Too many requests. Please try again later.",
    "retryAfter": 15
  }
}
```

### Best Practices

1. **Check headers** - Monitor remaining quota proactively
2. **Implement backoff** - Use exponential backoff on 429 errors
3. **Queue requests** - Buffer requests during high load
4. **Use webhooks** - Avoid polling by using webhook callbacks for Crawl and Batch APIs
5. **Leverage caching** - Cached responses don't count against quota

### Example: Exponential Backoff

```javascript
async function scrapeWithRetry(url, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    const response = await fetch('https://server.anyhunt.app/api/v1/scrape', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ url }),
    });

    if (response.status !== 429) {
      return response.json();
    }

    const retryAfter = response.headers.get('Retry-After') || Math.pow(2, i);
    await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
  }

  throw new Error('Max retries exceeded');
}
```

## Quota Management

### Check Remaining Quota

View your current quota usage in the [Anyhunt Console](https://console.anyhunt.app). The dashboard shows:

- Current plan and monthly quota
- Used and remaining credits
- Usage breakdown by API type
- Quota reset date

### Cache Hits Don't Count

When content is served from cache, it doesn't count against your quota. Check the `fromCache` field in responses:

```json
{
  "data": {
    "id": "scrape_abc123",
    "fromCache": true
  }
}
```

### Failed Requests Refunded

If a request fails (timeout, blocked URL, etc.), the quota is automatically refunded.

## Optimizing Usage

### Use Appropriate APIs

Choose the right API for your use case:

| Use Case | Recommended API |
|----------|-----------------|
| Single page content | Scrape API |
| Multiple known URLs | Batch Scrape API |
| Discover all site URLs | Map API |
| Crawl and extract | Crawl API |
| Structured data extraction | Extract API |
| Find content on web | Search API |

### Batch Similar Requests

Instead of multiple Scrape calls:

```javascript
// Inefficient: 10 separate calls
for (const url of urls) {
  await scrape(url);
}

// Efficient: 1 batch call
await batchScrape(urls);
```

### Leverage Caching

Default cache duration is 1 hour. Identical requests within this window are served from cache at no cost.

## Need Higher Limits?

- **Upgrade your plan** - Higher plans have higher limits
- **Contact sales** - For custom enterprise limits
- **Optimize usage** - Batch similar URLs, leverage caching

## Error Codes

| Error | HTTP Status | Description |
|-------|-------------|-------------|
| `RATE_LIMITED` | 429 | Too many requests per minute |
| `QUOTA_EXCEEDED` | 429 | Monthly quota exhausted |
| `CONCURRENCY_EXCEEDED` | 429 | Too many concurrent operations |

See [Error Handling](/docs/guides/error-handling) for retry strategies.
